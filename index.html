<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
      }
      .remark-slide-content h1 { font-size: 4.5em; }
      .remark-slide-content h2 { font-size: 2.5em; }
      h3 { font-size: 1.6em; }
      
      li p { line-height : 1.5em; }
      li { line-height: 1.5em;
           font-size: 1.5em;
      }

      .red { color: #fa0000}
      .orange { color: rgb(218, 134, 6);}
      .green { color: rgb(55, 126, 39);}
      .blue {color: rgb(39, 86, 151);}

      .small-font{
        font-size: 0.6em;
        line-height: 0.4em;
      }

      .right-column{
        width: 50%;
        float: right;
        
      }

      .right-column li {
        font-size: 1.2em;
        line-height: 0.8em;

      }
      .left-column{
        width: 50%;
        float: left; 
      }

      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

Progress Report
===============

## Mei-Hua ##
#### 2014.07.30 ####

---

## Aim

* Use previous methods to analyze Chinese data

---

## Corpus

* kimo blog data ( 2006/07/01 ~ 2007/06/30 )
![alt text](img/kimo_example.png)

---

## Corpus

* different from LJ40K: </br>
sentences with emoticon </br>

* full of special characters, unnecessary punctuation marks </br>

---

## Finished Progress
  
* store raw data into database 

* tokenize sentences with CKIP tokenizer

* use standford parser to get dependency relationship

* extract patterns 

* build lexicon

---

## Progressing

* tfidf: for keyword identifying

* svm

---
## Problems - Tokenization

* Stanford parser performs bad on Chinese sentences tokenizing. </br>
.orange[->] Use CKIP instead

* Some sentences with lots of punctuation mark cannot be tokenized. </br>
Examples: .small-font[如果你需要時間好好冷靜的思考.......沒關係......我願意等你.......無論多久我都會等你........等你準備好了.........等你願意見我....... 我不會再讓你擔心.......我也會按時吃飯........也會好好照顧自己.......你說的我都答應你........真的.......我說的都是真的.........請你相信 我.......... 小黑豬不會和小白豬分開的......就算有........也只是短暫的]




---

## Problems - Pattern Extraction

* Chinese grammar is quite different from English one. </br>

  .orange[->] We need to find new pattern rule instead.


---

## Problems - Pattern Extraction

* Patterns we want to extract: </br>
  我(sub) 很(adv) .green[開心(v)] </br>
  我(sub) .green[是(v)] 白痴(n) </br> 
  我(sub) .green[吃(v)] 了 一 隻 牛(obj) </br>


---

## Problems - Pattern Extraction

* Strange things happens: </br>
  我(sub) .green[肚子(v)] 痛(obj) </br>
  事(sub) .green[做(v)]

* Patterns we do not want: </br>
  後來 很(adv) .green[快(v)] </br>
  估(adv) .green[耐(v)]



---

## Problems - Pattern Extraction

* CKIP tokenizer may not tokenize the sentence well

* Stanford parser is not suitable for Chinese data

* Need to find a new way to generate good patterns for Chinese

---

## Problems - Feature Extraction
.left-column[ ![alt text](img/feature_extract.png) ]
.right-column[
* difficult to find repeated patterns in one sentence, because sentence is too short

* many patterns appear in only one emotion category </br>
.orange[->] useless for training models
]

---

## Problems

* Need to redefine "document" </br>
.red[✘] treat sentence as document 

---
class: center, middle

Questions or Comments :)
=============


    </textarea>
    <script src="http://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>